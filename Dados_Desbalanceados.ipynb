{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dados Desbalanceados.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfab/sigmoidal_ai/blob/master/Dados_Desbalanceados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4kh4P2xp5T6",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title\n",
        "# suprimir os warnings\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "!pip install -q scikit-plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxToYot_F4p",
        "colab_type": "text"
      },
      "source": [
        "# Como lidar com dados desbalanceados\n",
        "\n",
        "Saber como lidar com dados desbalanceados pode fazer toda a diferença no no seu projeto de *Data Science* e no desempenho do seu modelo de *Machine Learning*.\n",
        "\n",
        "Você provavelmente já se deparou com a situação de encontrar um *dataset* onde havia um nítido desequilíbrio entre as amostras de suas diferentes classes.\n",
        "\n",
        "Alguns exemplos de situações onde o desbalancemaneto é quase certo são problemas de detecção de fraude e diagnóstico médicos - é intuitivo pensar que existem mais transações lícitas que criminosas, ou que o conjunto de pessoas diagnosticadas com câncer é bem menor que o conjunto de pessoas sem a doença.\n",
        "\n",
        "Ignorar esse fato e treinar um algoritmo em cima do conjunto de dados original, pulando uma etapa intermediária de balanceamento dos dados, pode ter impactos diretos no seu projeto de *Data Science*.\n",
        "\n",
        "## Consequências dos dados desbalanceados\n",
        "\n",
        "Se você está construindo um modelo de *machine learning* para classificação, por exemplo, a consequência desse desequilíbrio é que o modelo terá uma tendência a dar muitos \"alarmes falsos\".\n",
        "\n",
        "Ou seja, na prática ele irá responder muito bem entradas para as classes majoritárias, mas terá um desempenho inferior para as minoriárias.\n",
        "\n",
        "No exemplo de detecção de fraude com cartões de crédito (onde o número de transações financeiras normais é bem maior que o número de transações fraudulentas), um classificador tenderá a apresentar muitos falsos negativos - uma situação indesejável para um banco, obviamente.\n",
        "\n",
        "Em um *trade-off*, seria preferível \"errar para mais\" e ter uma quantidade maior de falsos negativos. Aliás, aposto que você já teve seu cartão bloqueado preventivamente e teve que ligar no banco para confirmar as últimas compras que havia feito, não é mesmo?!\n",
        "\n",
        "Teoricamente, um *dataset* que possua qualquer classe com mais de 50% das entradas já é considerado desbalanceado. No entanto, há situações extremas onde você vai encontrar proporções maiores que 99:1.\n",
        "\n",
        "Existem várias abordagens para lidar com dados desbalanceados, cada uma com seus prós e contras. Neste artigo, irei mostrar alguns dos métodos mais populares para você incluir desde já no seu arsenal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3aLdMqhJ9U0",
        "colab_type": "text"
      },
      "source": [
        "## Métodos para lidar com *datasets* desbalanceados\n",
        "\n",
        "Há diversas maneiras para atacar o problema de dados desbalanceados, que envolvem desde a construção de algoritmos específicos até  a aplicação de algoritmos mais avançados como *Recognition-based Learning* e *Cost-sensitive Learning*. \n",
        "\n",
        "No entanto, uma outra abordagem bem mais simples tem sido amplamente usada (com ótimos resultados), a abordagem *sampling*.\n",
        "\n",
        "*Sampling* é um pré-processamento que visa minimizar as discrepâncias entre as classes por meio de uma reamostragem do *dataset* original. Para gerar um conjunto balanceado, são usadas normalmente as seguintes técnicas:\n",
        "\n",
        "* ***Over-sampling:*** cria novas observações da classe minoritária a partir das informações contidas nos dados originais. Essa geração de novas entradas pode ser feita aleatoriamente com o auxílio de técnicas de *clustering* ou sinteticamente.\n",
        "\n",
        "* ***Under-sampling:*** reduz o desbalanceamento do *dataset* focando na classe majoritária. Ou seja, elimina aleatoriamente entradas da classe com maior número de ocorrências.\n",
        "\n",
        "Além dessas duas técnicas de *sampling*, [existem também os *advanced sampling methods*](https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5), como SMOTE e ADASYN, onde instâncias são adicionadas ou removidas adaptativamente. \n",
        "\n",
        "Caso tenha curiosidade em conhecer mais e se aprofundar no assunto, [recomendo o este artigo científico](https://ro.uow.edu.au/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1806&context=infopapers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs05sfWnRdbI",
        "colab_type": "text"
      },
      "source": [
        "## Vantagens e desvantagens de cada técnica\n",
        "\n",
        "[O Teorema *No Free Lunch*](https://www.kdnuggets.com/2019/09/no-free-lunch-data-science.html) diz que não existem um perfeito e único, apenas com vantagens. Cada escolha uma renúncia, isso é *Data Science*. Quando você opta por uma abordagem, tem que estar ciente das limitações e implicações nos seus resultados -  e transmitir isso para os *stakeholders*.\n",
        "\n",
        "*Over-sampling* replica os dados já existentes, aumentando o número de instâncias das classes minoritárias. A vantagem é que nenhuma informação é descartada, porém o custo computacional será elevado e você irá deteriorar a performance do algoritmo para as classes minoritárias.\n",
        "\n",
        "Já o *Under-sampling* vai extrair um subconjunto aleatório da classe majoritária, preservando as características da classe minoritária, sendo ideal para situações onde você tem grandes volumes de dados. Apesar de reduzir o tempo computacional e de armazenamento, esta técnica descarta informações da classe majoritária, o que pode levar a uma performance inferior nas predições dela.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6witNH3YnQL",
        "colab_type": "text"
      },
      "source": [
        "## Balanceando dados na prática\n",
        "\n",
        "Para mostrar como balancear um *dataset* na prática, vou usar dados públicos de transações financeiras disponibilizados por empresas de cartões de crédito [neste link](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
        "\n",
        "Como é característico desse tipo de problema, as instâncias possuem distribuições bem discrepantes entre as classes `normal` (0) e `fraude` (1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSzEi-Uf36uH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ded98365-da13-429c-9aed-cad47b0c0802"
      },
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# configurar o estilo dos gráficos com o Seaborn\n",
        "sns.set_style('dark')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlurrDo9r8c7",
        "colab_type": "text"
      },
      "source": [
        "Acima, importei todas as bibliotecas que serão usadas neste artigo. Na sequência, importei o arquivo `csv` para dentro de um estrutura *dataframe* do `pandas` e imprimir a contagem de valores únicos para os *labels*.\n",
        "\n",
        "Representando 0,17% do total de instâncias, é nítida a discrepância e desbalanceamento dos dados. Mal conseguimos ver a barra da nossa variável alvo para instâncias de fraude (`df.Class == 1`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pczi3ydsJJ8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "536281ab-94ff-4c47-f6c5-420d936c8c25"
      },
      "source": [
        "file_path = \"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1\"\n",
        "\n",
        "# importar os dados para um dataframe\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# ver o balanceamento das classes\n",
        "print(df.Class.value_counts())\n",
        "print(\"\\nFraudes representam {:.4f}% do dataset.\\n\".format((df[df.Class == 1].shape[0] / df.shape[0]) * 100))\n",
        "\n",
        "# plotar gráfico de barras para as Classes\n",
        "sns.countplot('Class', data=df);"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "Fraudes representam 0.1727% do dataset.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns34AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47wqy5h2ZyPG",
        "colab_type": "text"
      },
      "source": [
        "Para você ter um ideia real das consequências dessa situação, vou construir dois modelos de Regressão Logística.\n",
        "\n",
        "No nosso primeiro modelo, separei as variáveis `X` e `y` normalmente e dividi entre conjuntos de treino e teste, como é praxe em *machine learning*. Sem maiores ajustes, treinei o modelo usando o método `fit(X_train, y_train)` e fiz a previsão de valores em cima do conjunto de teste (`X_test`).\n",
        "\n",
        "Na sequência, plotei a matriz de confusão e o relatório de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TkPdBDsKPr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "4428cfb1-8056-4dc0-ae93-12c6da4db0a3"
      },
      "source": [
        "# separar variáveis entre X e y\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# dividir o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True)\n",
        "\n",
        "# instanciar e treinar um modelo de Regressão Logística\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# fazer as previsões em cima dos dados de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)\n",
        "\n",
        "# plotar a matrix de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True)\n",
        "\n",
        "# imprimir relatório de classificação\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "# imprimir a área sob a curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, y_pred)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4891bcca5910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# plotar a matrix de confusão\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mskplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# imprimir relatório de classificação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'skplt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASTJvAo_ARVc",
        "colab_type": "text"
      },
      "source": [
        "Conseguimos uma acurácia de 99,88% no nosso modelo de *machine learning*. **Você considera esse um bom resultado?**\n",
        "\n",
        "Bem,  acurácia global foi alta, mas o que dizer daquele fator que mais importava para nós, a **capacidade de detectar fraudes no cartão de crédito?**\n",
        "\n",
        "Aí é outra história... por causa do desbalanceamento de dados, o modelo foi capaz de classificar bem as instâncias onde `df.Class == 0` (transações normais), mas acertou menos de 60% dos casos em que `df.Class == 1`.\n",
        "\n",
        "Vamos ver agora qual seria o resultado caso tivessemos usado a técnica ***Under-sampling***. Para facilitar esse pré-processamento, vou usar a biblioteca `imblearn` com sua classe `imblearn.under_sampling.RandomUnderSampler` e chamar o método `fit_sample(X_train, y_train)`.\n",
        "\n",
        "Note como eu estou usando o *under-sampling* em cima do conjunto de treino, e não de todos os dados. Isso é muito importante para não desconfigurarmos a característica de teste original do *dataset*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq1AQzLaMHz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usar técnica under-sampling\n",
        "rus = RandomUnderSampler()\n",
        "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
        "\n",
        "# ver o balanceamento das classes\n",
        "print(pd.Series(y_res).value_counts())\n",
        "\n",
        "# plotar a nova distribuição de classes\n",
        "sns.countplot(y_res);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EnKulTPEDxX",
        "colab_type": "text"
      },
      "source": [
        "O novo conjunto está corretamente balanceado agora, eliminando boa parte do problema que tínhamos inicialmente.\n",
        "\n",
        "Novamente, vou instanciar um novo modelo de Regressão Logística e treiná-lo nesses dados balanceados. Vamos dar uma olhada nas métricas de avaliação que foram usadas, e ver o que mudou."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AW-3P7Lqkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instanciar e treinar um modelo de Regressão Logística\n",
        "model_res = LogisticRegression()\n",
        "model_res.fit(X_res, y_res)\n",
        "\n",
        "# fazer as previsões em cima dos dados de teste\n",
        "y_pred_res = model_res.predict(X_test)\n",
        "y_proba_res = model_res.predict_proba(X_test)\n",
        "\n",
        "# plotar a matrix de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_res, normalize=True)\n",
        "\n",
        "# imprimir relatório de classificação\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_res, digits=4))\n",
        "\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, y_pred_res)))\n",
        "\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, y_pred_res)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFg6l4qvO8W8",
        "colab_type": "text"
      },
      "source": [
        "Repare que apesar da acurácia ter diminuído minimamente, tivemos um aumento significativo na capacidade do modelo em detectar fraudes. \n",
        "\n",
        "Apenas pelo fato de balancearmos os dados, melhoramos diversos parâmetros como `recall` e a área sob a curva (AUC), que são métricas extremamente importantes para o problema que estamos lidando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLEQTUaziSwB",
        "colab_type": "text"
      },
      "source": [
        "## Balanceamento de dados no mundo real\n",
        "\n",
        "São diversos os motivos que permitem que os dados sejam desbalanceados. Pode ser que o cientista de dados não conseguiu coletar igualmente dados de cada classe, ou pode ser que a amostra realmente refleta a população.\n",
        "\n",
        "Independente dos motivos, o não tratamente desse desbalanceamento afeta negativamente o desempenho do modelo, refletindo na qualidade global do seu projeto de *Data Science*.\n",
        "\n",
        "Não existe um método universal e ótimo. Existem técnicas que evoluem constantemente, e cabe a você identificar os prós e contras de cada uma.\n",
        "\n",
        "Por isso, recomendo não acompanhar apenas sites como o Kaggle, mas também acompanhar *papers* e trabalhos acadêmicos que tragam pesquisas nessa área tão importante."
      ]
    }
  ]
}